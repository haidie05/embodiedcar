编译
colcon build --symlink-install

conda create -n embodiedcar python=3.8
conda activate embodiedcar
电机引脚：
            "left_back": Motor(forward=27, backward=18),
            "left_front": Motor(forward=6, backward=5),
            "right_front": Motor(forward=19, backward=13),
            "right_back": Motor(forward=16, backward=12)

查看实时拍摄照片
浏览器登陆：
http://172.20.10.7:8080/?action=stream
树莓派上执行命令：
./mjpg_streamer -i "./input_uvc.so -d /dev/video0 -r 640x480 -f 10" -o "./output_http.so -w ./www"


帧率调试：
提高帧率
./mjpg_streamer -i "./input_uvc.so -d /dev/video0 -r 640x480 -f 20" -o "./output_http.so -w ./www"
降低分辨率
./mjpg_streamer -i "./input_uvc.so -d /dev/video0 -r 320x240 -f 20" -o "./output_http.so -w ./www"
参数含义：
- -d /dev/video0：从树莓派连接到的第一个摄像头（在咱这就只有一个摄像头）获取视频流
- -r 640x480：图像的分辨率是 640*480 像素（这个分辨率可以调整，通常不是奇数就都可以）
- -f 10：视频的帧率是 10 帧每秒（后面我们会从视频流读取帧并运行目标检测算法，如果你的 CPU 运行比较慢，目标检测看到明显的延迟和卡顿，可以把这个数值调小）

视觉部分文件夹：
mkdir -p  ~/VISUAL/src
cd VISUAL/src

如何运行：
一个终端运行
cd VISUAL
source install/setup.bash # 激活环境
ros2 run yolo yolo_control # 运行节点
另一个终端运行：
cd mjpg-streamer/mjpg-streamer-experimental
./mjpg_streamer -i "./input_uvc.so -d /dev/video0 -r 640x480 -f 10" -o "./output_http.so -w ./www"
在电脑端输入
python rasp_yolo.py


写代码：
编译
cd .. # 返回到WORKSPACE文件夹，这时候你应该看到你在 HAPPYPROJECT 目录下
colcon build --symlink-install # 编译


正确关机：
sudo shutdown -h now

python3 test.py --img E:\embodiedcar\Yolo-FastestV2\img\000139.jpg

修改时需要注意的点
1. 树莓派的IP地址
2. 绝对路径前面增加一个r就可以防止识别报错


使用mediapipe进行推理的时候python版本太低了所以新建了一个python=3.9的环境叫做embodiedmediapipe
wget -O pose_landmarker.task -q https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task

wget -O pose_landmarker.task -q https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task
